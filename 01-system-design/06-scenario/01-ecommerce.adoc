= Multi-Channel Product Updates Architecture
:toc: macro
:toclevels: 2
:sectnums:
:icons: font
:source-highlighter: rouge

This document outlines a system architecture for managing multi-channel product updates. It ingests vendor data, adjusts pricing with a repricer, and sends updates to marketplaces like Amazon and eBay.

== System Architecture

=== C1 Context Diagram

[source, mermaid]
----
C4Context
title üõí Multi-Channel Product Update System ‚Äì Context Diagram

Person(vendor, "üßë Vendor", "Sends product updates via API, FTP, or email")
Person(internalOps, "üë©‚Äçüíº Internal Operator", "Monitors and configures pricing rules")
System(system, "üõçÔ∏è Product Update System", "Processes and dispatches product updates to marketplaces")
System_Ext(marketplace, "üè¨ Marketplace Platform", "Receives updates from the internal system")

Rel(vendor, system, "üì§ Sends product & inventory updates")
Rel(internalOps, system, "‚öôÔ∏è Manages pricing and monitors system")
Rel(system, marketplace, "üì¶ Pushes inventory and pricing updates")
----

=== C2 Container Diagram

[source, mermaid]
----
C4Container
title üß© Product Update System ‚Äì Container Diagram

Person(vendor, "üßë Vendor")

System_Boundary(productUpdateSystem, "üõçÔ∏è Product Update System") {
  Container(ingestion, "üîå Ingestion Service", "Apache Camel / Spring Integration", "Handles API, FTP, and email inputs")
  Container(queue, "üì® Queueing System", "Kafka / RabbitMQ", "Decouples ingestion from processing")
  Container(preprocessor, "üßπ Preprocessing Service", "Spring Boot / Quarkus", "Cleans and normalizes data")
  Container(repricer, "üßÆ Repricer Engine", "Drools / Custom Logic", "Applies pricing rules based on cost and business strategy")
  Container(dispatcher, "üì§ Marketplace Dispatcher", "Micronaut / Spring WebClient", "Sends updates to marketplaces like Amazon, eBay")
  Container(cache, "‚ö° Price Cache", "Redis", "Stores temporary price decisions")
  Container(storage, "üíæ Persistent Storage", "PostgreSQL / MinIO", "Stores raw and processed update data")
  Container(monitoring, "üìä Monitoring & Alerting", "Prometheus + Grafana", "Tracks health metrics and errors")
  Container(errorHandler, "‚ùå Error Handler", "Standalone Service", "Handles retries, dead-letter queues, and logging")
}

System_Ext(marketplace, "üè¨ Marketplace Platform", "Amazon, eBay, etc.")

Rel(vendor, ingestion, "üì§ Sends product updates")
Rel(ingestion, queue, "üì® Publishes messages")
Rel(queue, preprocessor, "üîÅ Sends message for cleaning")
Rel(preprocessor, repricer, "üìä Sends normalized data")
Rel(repricer, cache, "‚ö° Caches price data")
Rel(repricer, dispatcher, "üì§ Sends repriced updates")
Rel(dispatcher, marketplace, "üöö Pushes updates")
Rel(dispatcher, storage, "üìù Logs update results")
Rel(preprocessor, storage, "üóÉÔ∏è Stores raw input")
Rel(dispatcher, errorHandler, "‚ùå Reports failures")
Rel(errorHandler, queue, "üîÅ Requeues for retry")
Rel(errorHandler, monitoring, "üì¢ Triggers alerts")
----

=== System Integration Flow

[source, mermaid]
----
graph TD
  subgraph Vendors
    A1[üîå API Input] --> I[üõ†Ô∏è Ingestion Layer]
    A2[üìÇ FTP Listener] --> I
    A3[üìß Email Parser CSV] --> I
  end

  I --> Q[üì® Kafka / RabbitMQ Queue]

  Q --> P[üßπ Preprocessing Service]
  P --> S1[(üíæ Raw Data Storage - MinIO)]
  P --> V[üß™ Validation & Normalization]
  V --> R[üßÆ Repricer Service]
  R --> S2[(‚ö° Price Cache - Redis)]
  R --> D[(üì¶ Final Update Queue)]

  D --> M1[üõí Amazon Sync Service]
  D --> M2[üõçÔ∏è eBay Sync Service]
  D --> M3[üè¨ Other Channels]

  M1 --> O1[(üîÅ API Response)]
  M2 --> O2
  M3 --> O3

  subgraph Monitoring & Reliability
    E1[‚ùå Error Queue]
    E2[üîÅ DLQ / Retry Logic]
    E3[üìä Alerting Prometheus + Grafana]
  end

  M1 -->|‚ùó Failure| E1
  M2 -->|‚ùó Failure| E1
  E1 --> E2
  E2 --> Q
  E2 --> E3
----


== Data Flow Breakdown

[source, mermaid]
----
graph LR
  subgraph Ingestion
    A1[üîå API Input]
    A2[üìÇ FTP Listener]
    A3[üìß Email Parser CSV]
    A1 --> I[üõ†Ô∏è Ingestion Service]
    A2 --> I
    A3 --> I
  end

  I --> Q[üì® Kafka / RabbitMQ Queue]

  subgraph Processing
    Q --> P[üßπ Preprocessor]
    P --> N[üß™ Normalization]
    N --> S1[(üíæ Raw Data Backup - MinIO)]
  end

  N --> R[üßÆ Repricer Engine]
  R --> C[‚ö° Redis Price Cache]

  subgraph Dispatch
    R --> UQ[üì¶ Final Update Queue]
    UQ --> D1[üõí Amazon Worker]
    UQ --> D2[üõçÔ∏è eBay Worker]
    UQ --> D3[üè¨ Other Marketplace Worker]
  end

  D1 --> A1Resp[(üîÅ Amazon API Resp)]
  D2 --> A2Resp[(üîÅ eBay API Resp)]
  D3 --> A3Resp[(üîÅ Other Resp)]

  subgraph Failure Handling
    D1 -->|‚ùó Fail| E1[‚ùå Error Queue]
    D2 -->|‚ùó Fail| E1
    D3 -->|‚ùó Fail| E1
    E1 --> E2[üîÅ DLQ & Retry Service]
    E2 --> Q
  end

  subgraph Monitoring & Observability
    I --> M[üìä Metrics Prometheus]
    P --> M
    R --> M
    D1 --> M
    E1 --> M
    E2 --> M
  end
----

=== 1. Vendor Ingestion Layer

- **API**: REST endpoints for structured input
- **FTP Listener**: Scheduled job polling vendor files
- **Email Parser**: Extracts CSV from email attachments
- Normalized into a unified schema and sent to Kafka or RabbitMQ for decoupling and backpressure.

=== 2. Processing & Repricing

- **Preprocessing**: Cleans and validates incoming payloads.
- **Raw Storage**: S3-compatible store (e.g., MinIO) for auditing and reprocessing.
- **Repricer**: Applies pricing strategies using input cost, competition, and business rules.
- **Cache**: Redis for fast access to recent pricing decisions.

=== 3. Update Dispatch

- **Dispatch Queue**: Stores final update payloads.
- **Channel Workers**: One per marketplace (Amazon, eBay, etc.), using async non-blocking HTTP clients like `WebClient` or `Apache HttpAsyncClient`.
- **Rate Limiting**: Use of a `resilience4j`-based circuit breaker or retry policy.

=== 4. Error Handling & Observability

- **Error Queue**: Captures failures to isolate processing.
- **DLQ / Retry Logic**: Attempts reprocessing with exponential backoff.
- **Prometheus + Grafana**: Metric scraping and dashboards.
- **Structured Logs**: Output JSON logs via OpenTelemetry or Logstash-compatible format.

== ‚òÅÔ∏è Scalability Considerations

- Kafka/RabbitMQ enable **horizontal scaling** of workers.
- Stateless microservices (e.g., using Spring Boot or Quarkus) can be **scaled independently**.
- Redis + S3 provide separation between fast lookup and deep storage.

== üîß Technology Stack (Open Source)

- **Ingestion**: Apache Camel / Spring Integration
- **Queueing**: Apache Kafka or RabbitMQ
- **Processing**: Quarkus / Micronaut / Spring Boot
- **Storage**: PostgreSQL for metadata, MinIO for object store
- **Repricing**: Business Rule Engine (Drools or custom)
- **Cache**: Redis
- **Observability**: Prometheus, Grafana, Loki
- **Orchestration**: Kubernetes (K8s)
- **Retry / Circuit Breaker**: Resilience4j

== üõ† Design Choices

- *Event-driven architecture*: Enables decoupling and asynchronous processing.
- *Polyglot persistence*: Combines cache, object store, and relational DBs for performance and flexibility.
- *Replayability*: Kafka topics and raw data storage allow easy replay on failure.
- *Cloud-native ready*: Designed for containerized environments with horizontal scalability.

== ‚öñÔ∏è Trade-offs and Design Decisions

- **Open-source vs. managed services**:
Chose open-source tools (Kafka, Redis, MinIO) for neutrality and control.
‚Üí Trade-off: full responsibility for scaling and ops.

- **State in cache/queue vs. database**:
Handled transient state (e.g., repricing, retries) via Redis and Kafka for throughput and decoupling.
‚Üí Trade-off: more distributed coordination, eventual consistency.

- **Rule-based vs. static repricing**:
Enabled Drools and custom logic for flexible pricing strategies.
‚Üí Trade-off: higher complexity and need for business rule governance.

- **Internal scalability vs. API constraints**:
System scales horizontally, but marketplaces impose rate limits.
‚Üí Trade-off: real-world throughput is gated by external dependencies.
